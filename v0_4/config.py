# Latest api version
LATEST_API = 'v0.3'

# Cron schedule timing(second)
CRAWL_INTERVAL = 5

# Crawl attempt max pages
CRAWL_MAX_ATTEMPT = 200

# Ver 0.3
# Cache using
USING_CACHE = True

# Log Using
DEBUG_LOGGING = False

# Threaded Crawling
CRAWL_THREADED = False

# Number of urls to parse per spider
CRAWL_CAPACITY = 20

# Max number of cached urls to check duplicates. recommend >= 200, at least 100.
MAX_CACHED_URLS = 500

TEST_TEXT = "I'm Here in version folder"
